# Alarm Chatbot (FastAPI + RAG + LLM)

A **Retrievalâ€‘Augmented Generation (RAG) based Alarm Chatbot** built with **FastAPI**, **ChromaDB**, and a **local LLM (llama.cpp)**.
The system allows users to upload alarm data via Excel files and ask questions to get **fast, reliable, and domainâ€‘specific answers**.

This project is structured into a **Backend (API + RAG logic)** and a **Frontend (Web UI)**.

---

## ğŸ“ Project Structure

```
Chatbot/
â”œâ”€â”€ Backend/
â”‚   â”œâ”€â”€ Model/
â”‚   â”œâ”€â”€ app.py              # FastAPI entry point
â”‚   â”œâ”€â”€ ingest.py           # Excel ingestion script
â”‚   â”œâ”€â”€ model.py            # LLM loading (llama.cpp)
â”‚   â”œâ”€â”€ rag.py              # RAG logic (prompt + LLM call)
â”‚   â””â”€â”€ vectorstore.py      # ChromaDB & embedding logic
â”‚
â”œâ”€â”€ Frontend/
â”‚   â”œâ”€â”€ icons/              # UI icons
â”‚   â”œâ”€â”€ Beumer_logo_W.png
â”‚   â”œâ”€â”€ Logo-BEUMER-Group.webp
â”‚   â”œâ”€â”€ app.js              # Frontend logic
â”‚   â”œâ”€â”€ index.html          # Main UI
â”‚   â””â”€â”€ style.css           # Styling
â”‚
â””â”€â”€ README.md
```

---

## ğŸš€ Features

* Upload alarm data using Excel (`.xlsx`)
* Strict alarm code validation (no guessing)
* Vectorâ€‘based semantic search (ChromaDB)
* Exact alarm code matching for ultraâ€‘fast lookup
* Local LLM inference (CPUâ€‘only, fast & secure)
* Clean webâ€‘based frontend UI

---

## âš™ï¸ Backend Overview

### `app.py`

* FastAPI application entry point
* Exposes APIs:

  * `/upload-excel` â†’ Upload & ingest Excel
  * `/ask` â†’ Ask alarmâ€‘related questions

---

### `ingest.py`

* Commandâ€‘line Excel ingestion utility
* Validates:

  * File existence
  * `.xlsx` format
  * Required columns (`alarm no`, `alarm description`)
* Loads data into the vector database

---

### `vectorstore.py`

* Handles:

  * Alarm code cleaning & validation
  * Embedding generation
  * ChromaDB storage & retrieval
* Supports:

  * Exact alarm code search (metadata filter)
  * Semantic search (descriptionâ€‘based)

---

### `model.py`

* Loads the local LLM using **llama.cpp**
* Optimized for speed:

  * Small context window
  * CPUâ€‘only execution
  * Low memory usage

---

### `rag.py`

* Core RAG logic
* Builds a strict system prompt
* Sends retrieved alarm context to the LLM
* Ensures:

  * No hallucinations
  * Short, practical answers
  * Engineerâ€‘style responses

---

## ğŸŒ Frontend Overview

The frontend is a lightweight web UI built with **HTML, CSS, and JavaScript**.

### Key Files

* `index.html` â†’ Page structure
* `style.css` â†’ Styling & layout
* `app.js` â†’ API calls & chat logic
* `icons/` â†’ UI icons
* Logos included for branding

The frontend communicates with the FastAPI backend using HTTP requests.

---

## ğŸ§  How the System Works

### 1ï¸âƒ£ Excel Upload Flow

1. User uploads `.xlsx` file
2. Backend validates file & columns
3. Alarm rows converted into documents
4. Embeddings generated
5. Stored in ChromaDB

### 2ï¸âƒ£ Question Answer Flow

1. User asks a question
2. Alarm code detected (if present)
3. Exact match or semantic search
4. Context retrieved from vector DB
5. LLM generates grounded answer
6. Answer returned to UI

---

## ğŸ§ª Example API Usage

### Upload Excel

```
POST /upload-excel
```

### Ask Question

```json
{
  "question": "What is AL4024?"
}
```

---

## ğŸ› ï¸ Setup Instructions

### 0ï¸âƒ£ Model Requirement

This project uses a **local LLM model**:

```
mistral-7b-instruct-v0.1.Q4_K_M.gguf
```

**Steps:

### 0ï¸âƒ£ Model Requirement

This project uses a **local LLM model**:

```
mistral-7b-instruct-v0.1.Q4_K_M.gguf
```

**Steps:**

1. Create a folder named `models` inside `Backend`
2. Download the model file
3. Place it here:

```
Backend/models/mistral-7b-instruct-v0.1.Q4_K_M.gguf
```

> âš ï¸ The application will not start if the model f

### 1. Clone Repository

```bash
git clone https://github.com/ArchitShar1999/Chatbot.git
cd Chatbot
```

### 2. Backend Setup

#### Step 1: Create Virtual Environment

```bash
cd Backend
python -m venv .venv
```

#### Step 2: Activate Virtual Environment

```bash
.\\.venv\\Sc

---

## âš¡ Performance Highlights

- Exact alarm lookup before semantic search
- Small LLM context (fast inference)
- Low temperature (reliable answers)
- No internet dependency
- Optimized for realâ€‘time operations

---

## ğŸ“„ License

MIT License

---

## ğŸ‘¤ Author

**Archit Sharma**  
MCA | System & Automation Enthusiast  

---

## ğŸ”š Oneâ€‘Line Summary

**Excel â†’ Validate â†’ Embed â†’ ChromaDB â†’ Retrieve â†’ LLM â†’ Answer**

```
